{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cmap = np.load('submodule/lib_maeve_py/example/cmap.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from findpeaks import findpeaks\n",
    "cmap.shape\n",
    "\n",
    "cmap = np.squeeze(cmap)\n",
    "print(cmap.shape)\n",
    "\n",
    "for i in range(0,cmap.shape[0]):\n",
    "    fp = findpeaks()\n",
    "    a = fp.fit(cmap[i,:,:])\n",
    "    print(a)\n",
    "    fp.plot_preprocessing()\n",
    "    # Plot all\n",
    "    fp.plot_mesh()\n",
    "    print(np.max(cmap[i,:,:]), np.min(cmap[i,:,:]), )\n",
    "    plt.imshow(cmap[i,:,:], cmap='hot', interpolation='nearest')\n",
    "    \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mboldo/overgorund/.venv_new_overground/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mboldo/overgorund/.venv_new_overground/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 3.6587e-03,  4.3761e-04,  1.1300e-03,  ...,  4.0149e-03,\n",
       "             4.3075e-03,  2.3972e-03],\n",
       "           [ 3.2995e-03,  1.0897e-03,  1.3443e-03,  ...,  4.3846e-03,\n",
       "             4.6997e-03,  2.4177e-03],\n",
       "           [ 8.0810e-03,  4.7390e-03,  1.7744e-03,  ...,  5.3991e-03,\n",
       "             4.3186e-03,  3.6367e-03],\n",
       "           ...,\n",
       "           [ 3.4622e-04, -6.9760e-06,  1.1300e-05,  ...,  1.1591e-02,\n",
       "             1.0116e-02,  7.5477e-03],\n",
       "           [ 6.4360e-05,  1.4225e-05, -2.9062e-05,  ...,  7.1001e-03,\n",
       "             5.9553e-03,  4.2461e-03],\n",
       "           [ 2.6687e-05,  2.6944e-04,  1.0780e-04,  ...,  9.6094e-03,\n",
       "             9.6541e-03,  7.4912e-03]],\n",
       " \n",
       "          [[ 2.7967e-03,  1.3057e-03,  8.0101e-04,  ...,  3.6606e-03,\n",
       "             2.0745e-03,  5.5653e-03],\n",
       "           [ 3.3782e-03,  2.7752e-03,  1.9527e-03,  ...,  3.2891e-03,\n",
       "             2.2721e-03,  3.8748e-03],\n",
       "           [ 7.7097e-03,  9.4872e-03,  3.7070e-03,  ...,  3.1755e-03,\n",
       "             1.8048e-03,  3.0927e-03],\n",
       "           ...,\n",
       "           [ 3.7924e-04,  5.9638e-05,  3.9046e-05,  ...,  2.1498e-03,\n",
       "             4.6070e-03,  6.7368e-03],\n",
       "           [ 1.3127e-04,  9.5600e-05,  5.0108e-06,  ...,  2.3263e-03,\n",
       "             2.6749e-03,  4.4129e-03],\n",
       "           [ 9.0681e-04,  4.5700e-04,  3.0094e-04,  ...,  3.8166e-03,\n",
       "             4.1372e-03,  7.4670e-03]],\n",
       " \n",
       "          [[ 2.6604e-03,  9.2115e-04,  1.9906e-03,  ...,  9.5415e-04,\n",
       "             2.1279e-03,  6.6913e-04],\n",
       "           [ 2.6437e-03,  1.0291e-03,  1.6331e-03,  ...,  1.9634e-03,\n",
       "             1.2559e-03,  9.5079e-04],\n",
       "           [ 2.4135e-03,  1.2020e-03,  1.5309e-03,  ...,  3.2329e-03,\n",
       "             2.8602e-03,  1.5196e-03],\n",
       "           ...,\n",
       "           [ 2.9416e-04, -1.7980e-05,  1.5637e-05,  ...,  1.3125e-02,\n",
       "             5.7269e-03,  2.2311e-03],\n",
       "           [ 5.6891e-04,  2.3653e-05,  5.0853e-05,  ...,  9.0362e-03,\n",
       "             5.4052e-03,  2.2595e-03],\n",
       "           [ 3.6447e-04,  5.4137e-05,  6.8799e-05,  ...,  1.2227e-02,\n",
       "             6.1208e-03,  5.5132e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.1140e-03,  3.5335e-04,  1.4177e-03,  ...,  1.2014e-02,\n",
       "             6.8885e-03,  1.3919e-02],\n",
       "           [ 1.0900e-03,  1.3563e-04,  6.7518e-05,  ...,  1.2177e-02,\n",
       "             2.7545e-03,  3.4774e-03],\n",
       "           [ 1.0057e-03,  2.3845e-04,  1.1048e-04,  ...,  1.7522e-02,\n",
       "             1.0044e-02,  8.4253e-03],\n",
       "           ...,\n",
       "           [ 5.8601e-04,  1.9420e-04,  8.2929e-05,  ...,  5.8258e-03,\n",
       "             3.9665e-03,  6.4565e-03],\n",
       "           [ 4.6245e-04,  1.2057e-04,  3.2269e-05,  ...,  9.6546e-03,\n",
       "             9.1385e-03,  1.2541e-02],\n",
       "           [ 1.3364e-03,  9.6158e-05,  9.5370e-05,  ...,  6.9475e-03,\n",
       "             8.2206e-03,  1.6979e-02]],\n",
       " \n",
       "          [[ 2.5077e-03,  8.9622e-04,  8.7835e-04,  ...,  2.2410e-03,\n",
       "             1.9266e-03,  4.4542e-03],\n",
       "           [ 1.7409e-03,  9.4494e-05,  8.6144e-05,  ...,  5.0939e-03,\n",
       "             1.8779e-03,  1.6925e-03],\n",
       "           [ 2.3536e-04,  1.1471e-04,  1.8433e-04,  ...,  7.4069e-03,\n",
       "             2.6023e-03,  1.8096e-03],\n",
       "           ...,\n",
       "           [ 1.0930e-03,  4.0545e-04,  6.1841e-04,  ...,  8.4522e-03,\n",
       "             6.6858e-03,  8.6772e-03],\n",
       "           [ 1.1168e-03,  2.7692e-04,  1.3023e-04,  ...,  2.0128e-02,\n",
       "             1.6235e-02,  8.9999e-03],\n",
       "           [ 1.4736e-03,  2.7172e-04,  3.4565e-04,  ...,  3.8164e-02,\n",
       "             2.3371e-02,  2.7963e-02]],\n",
       " \n",
       "          [[ 5.9193e-04, -3.1326e-04,  3.5339e-04,  ...,  5.0334e-04,\n",
       "             1.7333e-03,  1.2643e-03],\n",
       "           [ 8.9465e-04,  1.0393e-04,  2.2176e-04,  ...,  4.0165e-03,\n",
       "             1.6046e-03,  8.3655e-04],\n",
       "           [ 7.5793e-05,  9.0778e-05,  1.8947e-04,  ...,  8.2148e-03,\n",
       "             2.0550e-03,  1.4839e-03],\n",
       "           ...,\n",
       "           [ 9.2964e-04,  3.9340e-04,  6.9727e-04,  ...,  6.8483e-03,\n",
       "             5.9618e-03,  6.9101e-03],\n",
       "           [ 7.6482e-04,  3.0638e-04,  1.4380e-04,  ...,  1.5780e-02,\n",
       "             1.6688e-02,  1.0076e-02],\n",
       "           [ 2.0811e-03,  3.5534e-04,  2.6685e-04,  ...,  2.0809e-02,\n",
       "             2.2686e-02,  3.7488e-02]]]], grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[[ 1.9176e-02,  2.1776e-02,  2.8014e-02,  ..., -8.5647e-02,\n",
       "            -4.0603e-02, -1.6925e-02],\n",
       "           [-5.6420e-02,  1.0314e-02, -2.3749e-03,  ..., -1.5315e-01,\n",
       "            -1.3147e-01, -1.7144e-01],\n",
       "           [-7.2233e-02,  1.4379e-02, -1.1390e-02,  ..., -1.8995e-01,\n",
       "            -1.9602e-01, -1.6747e-01],\n",
       "           ...,\n",
       "           [-2.1619e-02, -3.0299e-02,  1.2942e-03,  ...,  1.5037e-02,\n",
       "             6.9422e-03,  4.1442e-02],\n",
       "           [-3.8256e-02, -3.0626e-02, -5.7971e-03,  ..., -3.5822e-02,\n",
       "            -6.4622e-02, -9.1103e-02],\n",
       "           [-1.8617e-02, -5.0087e-02, -8.2277e-03,  ..., -6.4994e-02,\n",
       "            -1.0650e-01, -2.6773e-02]],\n",
       " \n",
       "          [[-1.3344e-02,  3.4579e-03, -1.8536e-03,  ..., -6.8312e-02,\n",
       "            -4.4962e-02, -4.0008e-02],\n",
       "           [ 3.0765e-03,  4.2304e-04,  4.5985e-03,  ..., -3.8439e-02,\n",
       "            -7.8050e-03, -3.0257e-02],\n",
       "           [-3.4897e-02,  7.7824e-03, -8.0844e-04,  ..., -7.2373e-02,\n",
       "            -3.6725e-02, -6.3870e-02],\n",
       "           ...,\n",
       "           [-1.0026e-02, -7.4134e-03, -9.1316e-04,  ...,  1.0955e-02,\n",
       "            -7.7363e-03,  3.5366e-02],\n",
       "           [-1.5932e-02,  4.6870e-04, -2.1487e-04,  ..., -8.0737e-03,\n",
       "            -3.8671e-02,  6.6665e-03],\n",
       "           [-9.9043e-03, -2.7863e-02, -1.2636e-03,  ..., -2.2764e-02,\n",
       "            -5.5645e-02, -1.9779e-02]],\n",
       " \n",
       "          [[-6.6508e-03,  2.8534e-02,  2.1943e-02,  ..., -1.7105e-01,\n",
       "            -9.0582e-02, -1.0595e-01],\n",
       "           [-1.3241e-01,  1.7660e-02, -2.0531e-03,  ..., -1.8838e-01,\n",
       "            -1.7209e-01, -1.8506e-01],\n",
       "           [-1.0714e-01,  2.6260e-02,  8.1973e-03,  ..., -2.5022e-01,\n",
       "            -2.2830e-01, -1.9541e-01],\n",
       "           ...,\n",
       "           [ 1.8454e-02, -1.1625e-02, -8.1671e-03,  ...,  2.8767e-02,\n",
       "             1.2141e-02,  3.8968e-02],\n",
       "           [ 1.5123e-02, -2.0103e-02,  6.8253e-03,  ..., -3.7548e-02,\n",
       "            -4.1104e-02, -8.3912e-02],\n",
       "           [-1.3505e-02, -2.6826e-02, -1.5022e-03,  ...,  1.3773e-02,\n",
       "            -2.1467e-02,  3.6383e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.3594e-02, -4.7908e-03,  7.9549e-04,  ...,  1.0083e-02,\n",
       "             7.0062e-02,  4.0152e-02],\n",
       "           [-1.3251e-02,  1.8218e-02, -5.4624e-03,  ...,  1.2559e-02,\n",
       "            -3.0069e-03,  3.7037e-02],\n",
       "           [-1.2073e-02, -1.4752e-02,  3.0251e-03,  ..., -1.5418e-02,\n",
       "             2.2524e-02,  4.4968e-02],\n",
       "           ...,\n",
       "           [ 9.8659e-03,  3.4736e-03,  5.9070e-03,  ...,  7.2090e-03,\n",
       "             4.4857e-03,  3.7039e-02],\n",
       "           [ 6.3352e-03, -3.6604e-03,  4.3431e-03,  ..., -9.8569e-02,\n",
       "            -8.0604e-02, -1.2423e-02],\n",
       "           [ 7.3286e-03,  1.1912e-02,  6.2181e-03,  ...,  2.0392e-02,\n",
       "             2.5708e-02,  3.0551e-02]],\n",
       " \n",
       "          [[-2.6160e-02, -2.9018e-02, -1.2931e-03,  ..., -6.1122e-02,\n",
       "            -3.4450e-02,  4.5404e-03],\n",
       "           [-2.2674e-02,  1.6398e-02,  4.1008e-03,  ...,  3.0229e-02,\n",
       "             3.8776e-02,  6.3182e-02],\n",
       "           [ 4.1541e-02,  2.0558e-02,  3.8160e-02,  ...,  3.2630e-02,\n",
       "             5.9146e-02,  4.2764e-02],\n",
       "           ...,\n",
       "           [ 1.0508e-02, -2.7580e-04,  2.9107e-03,  ..., -1.9464e-01,\n",
       "            -1.4435e-01, -1.1489e-01],\n",
       "           [ 5.2799e-03, -6.7313e-03, -2.6065e-03,  ..., -1.5489e-01,\n",
       "            -1.3123e-01, -1.9620e-02],\n",
       "           [ 9.9815e-03, -7.6128e-03,  7.8321e-04,  ..., -1.5317e-01,\n",
       "            -8.7920e-02,  1.1631e-02]],\n",
       " \n",
       "          [[-2.0711e-02, -8.1091e-03,  1.4528e-02,  ..., -2.6769e-02,\n",
       "            -1.2508e-02, -3.9994e-03],\n",
       "           [-2.6418e-02, -7.0682e-03, -2.8333e-03,  ...,  7.8914e-03,\n",
       "            -6.0612e-03,  1.9381e-03],\n",
       "           [-4.8799e-02, -2.3062e-02, -9.6911e-04,  ...,  1.4301e-02,\n",
       "             6.7018e-03,  1.3965e-02],\n",
       "           ...,\n",
       "           [ 5.8981e-04,  2.8377e-03,  6.7184e-03,  ...,  2.8310e-02,\n",
       "             4.2735e-02,  2.8157e-02],\n",
       "           [ 3.9576e-02,  9.2617e-03,  7.7029e-03,  ...,  1.8705e-02,\n",
       "             4.4786e-02,  1.0144e-02],\n",
       "           [-3.0943e-03, -4.5436e-03,  5.7082e-03,  ..., -1.3752e-02,\n",
       "            -2.6396e-02, -3.1805e-02]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from onnx2keras import onnx_to_keras\n",
    "from keras.models import load_model\n",
    "from trt_pose.trt_pose.models import MODELS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dummy_input = torch.ones( 1, 3, 256, 256).cpu()\n",
    "pt_model = MODELS[\"densenet121_baseline_att\"]( cmap_channels = 12, paf_channels = 24, upsample_channels = 256, num_upsample  = 3)\n",
    "pytorch_model = \"trt_pose/tasks/human_pose/experiments/prova_nohead_densenet121_baseline_att_256x256_B.json.checkpoints/epoch_0.pth\"\n",
    "checkpoint = torch.load(pytorch_model)\n",
    "pt_model.load_state_dict(checkpoint)\n",
    "\n",
    "#summary(pt_model, input_size=(1, 3, 256, 256), verbose=True)\n",
    "\n",
    "\n",
    "pt_model(dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tf2onnx.convert' has no attribute 'from_onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtf2onnx\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model_tf, _ \u001b[39m=\u001b[39m tf2onnx\u001b[39m.\u001b[39;49mconvert\u001b[39m.\u001b[39;49mfrom_onnx(model_onnx)\n\u001b[1;32m     26\u001b[0m tf2onnx\u001b[39m.\u001b[39msave\u001b[39m.\u001b[39mmodel_to_file(model_tf, \u001b[39m\"\u001b[39m\u001b[39mmodel_tf.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tf2onnx.convert' has no attribute 'from_onnx'"
     ]
    }
   ],
   "source": [
    "\n",
    "onnx_model = \"path_to_output_model.onnx\"\n",
    "\n",
    "torch.onnx.export(pt_model, dummy_input, onnx_model)\n",
    "\n",
    "onnx_model = onnx.load(\"path_to_output_model.onnx\")\n",
    "\n",
    "\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "\n",
    "# sess = rt.InferenceSession(\"path_to_output_model.onnx\")\n",
    "# input_name = sess.get_inputs()[0].name\n",
    "\n",
    "# # Note: The input must be of the same shape as the shape of x during # the model export part. i.e. second argument in this function call: torch.onnx.export()\n",
    "# onnxPredictions = sess.run(None, {input_name: dummy_input.cpu().numpy()})[0]\n",
    "# print(onnxPredictions)\n",
    "#keras_model = onnx_to_keras(onnx_model, ['input.1'],  name_policy='renumerate' )\n",
    "\n",
    "\n",
    "\n",
    "#keras_model.save(\"path_to_keras_model.h5\")\n",
    "import onnx\n",
    "\n",
    "import tf2onnx\n",
    "model_tf, _ = tf2onnx.convert.from_onnx(model_onnx)\n",
    "tf2onnx.save.model_to_file(model_tf, \"model_tf.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from onnx2keras import onnx_to_keras\n",
    "from keras.models import load_model\n",
    "from trt_pose.trt_pose.models import MODELS\n",
    "loaded_model = load_model(\"path_to_keras_model.h5\")\n",
    "loaded_model.summary()\n",
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model) # path to the SavedModel directory\n",
    "converter.allow_custom_ops = True\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(loaded_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "i = 0\n",
    "while i <100:\n",
    "    dummy_input = np.random.randn(1, 3, 256, 256)\n",
    "    loaded_model(dummy_input)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(pytorch_model)\n",
    "model = tf.keras.models.load_model(pytorch_model)\n",
    "\n",
    "#save_model(model,model_path + r\"\\new_model.h5\", save_format='h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overgroun3.8",
   "language": "python",
   "name": "overgroun3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
